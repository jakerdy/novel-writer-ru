```json
#!/usr/bin/env bash
# Ğ¡Ğ°Ğ¼Ğ¾ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ° Ğ½Ğ° Â«Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡Ğ½Ğ¾ÑÑ‚ÑŒÂ» (Ğ¾Ñ„Ğ»Ğ°Ğ¹Ğ½): Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ²ÑĞ·ÑƒÑÑ‰Ğ¸Ñ… ÑĞ»Ğ¾Ğ²/Ğ¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ·, ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ‹Ñ… ÑĞ»Ğ¾Ğ²

set -e

SCRIPT_DIR=$(dirname "$0")
source "$SCRIPT_DIR/common.sh"

PROJECT_ROOT=$(get_project_root)

FILE_PATH="$1"
if [ -z "$FILE_PATH" ] || [ ! -f "$FILE_PATH" ]; then
  echo "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: scripts/bash/text-audit.sh <Ñ„Ğ°Ğ¹Ğ»>"
  exit 1
fi

# Ğ’Ñ‹Ğ±Ğ¾Ñ€ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸: Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ spec/knowledge Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°, Ğ·Ğ°Ñ‚ĞµĞ¼ .specify/templates/knowledge
CFG_PROJECT="$PROJECT_ROOT/spec/knowledge/audit-config.json"
CFG_TEMPLATE="$PROJECT_ROOT/.specify/templates/knowledge/audit-config.json"
if [ -f "$CFG_PROJECT" ]; then
  CFG="$CFG_PROJECT"
elif [ -f "$CFG_TEMPLATE" ]; then
  CFG="$CFG_TEMPLATE"
else
  CFG=""
fi

python3 - "$FILE_PATH" "$CFG" << 'PY'
import json, re, sys, os, math

path = sys.argv[1]
cfg_path = sys.argv[2] if len(sys.argv) > 2 else ''

text = open(path, 'r', encoding='utf-8', errors='ignore').read()

default_cfg = {
  "connector_phrases": ["é¦–å…ˆ","å…¶æ¬¡","å†æ¬¡","ç„¶å","ç„¶è€Œ","æ€»è€Œè¨€ä¹‹","ç»¼ä¸Šæ‰€è¿°","åœ¨æŸç§ç¨‹åº¦","ä¼—æ‰€å‘¨çŸ¥","åœ¨å½“ä¸‹","éšç€"],
  "empty_phrases": ["å¹¿æ³›å…³æ³¨","å¼•å‘çƒ­è®®","å½±å“æ·±è¿œ","å…·æœ‰é‡è¦æ„ä¹‰","æœ‰æ•ˆæå‡","å…·æœ‰ä¸€å®šçš„æŒ‡å¯¼æ„ä¹‰","å€¼å¾—æˆ‘ä»¬æ€è€ƒ"],
  "cliche_pairs": [],
  "sentence_length": {"max_run_long":4, "max_run_short":5, "short_threshold":12, "long_threshold":35},
  "abstract_nouns": ["ä»·å€¼","æ„ä¹‰","è®¤çŸ¥","ä½“ç³»","æ¨¡å¼","è·¯å¾„","æ–¹æ³•è®º","è¶‹åŠ¿"],
  "min_concrete_details": 3
}

cfg = default_cfg
if cfg_path and os.path.exists(cfg_path):
  try:
    with open(cfg_path, 'r', encoding='utf-8') as f:
      loaded = json.load(f)
      cfg.update(loaded)
  except Exception:
    pass

def count_occurrences(text, phrases):
  res = {}
  for p in phrases:
    if not p: continue
    res[p] = len(re.findall(re.escape(p), text))
  return res

def split_sentences(t):
  parts = re.split(r'[ã€‚ï¼ï¼Ÿ!?\n]+', t)
  return [s.strip() for s in parts if s.strip()]

def sentence_lengths(sents):
  lens = [len(s) for s in sents]
  if not lens:
    return lens, 0, 0
  avg = sum(lens)/len(lens)
  var = sum((x-avg)**2 for x in lens)/len(lens)
  return lens, avg, math.sqrt(var)

def runs(lens, short_th, long_th):
  run_short = 0; run_long = 0
  max_run_short = 0; max_run_long = 0
  marks = []
  for i, L in enumerate(lens):
    if L <= short_th:
      run_short += 1; max_run_short = max(max_run_short, run_short); run_long = 0
    elif L >= long_th:
      run_long += 1; max_run_long = max(max_run_long, run_long); run_short = 0
    else:
      run_short = 0; run_long = 0
  return max_run_short, max_run_long

def abstract_density(sent, abstract_words):
  cnt = sum(len(re.findall(re.escape(w), sent)) for w in abstract_words)
  return cnt

connectors = count_occurrences(text, cfg["connector_phrases"])
empties = count_occurrences(text, cfg["empty_phrases"])
sents = split_sentences(text)
lens, avg, std = sentence_lengths(sents)
mx_run_short, mx_run_long = runs(lens, cfg["sentence_length"]["short_threshold"], cfg["sentence_length"]["long_threshold"])

abstract_scores = [(i, abstract_density(s, cfg["abstract_nouns"])) for i, s in enumerate(sents)]
abstract_scores.sort(key=lambda x: x[1], reverse=True)
abstract_top = [ (i, sents[i]) for i,score in abstract_scores[:5] if score>=2 ]

total_chars = len(text)
def ratio(count):
  return (count / max(1,total_chars)) * 1000

print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
print("ğŸ“Š ĞÑ‚Ñ‡Ñ‘Ñ‚ ÑĞ°Ğ¼Ğ¾Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ½Ğ° Â«Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡Ğ½Ğ¾ÑÑ‚ÑŒÂ» (Ğ¾Ñ„Ğ»Ğ°Ğ¹Ğ½)")
print(f"Ğ¤Ğ°Ğ¹Ğ»: {os.path.basename(path)}  ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²: {total_chars}")
print("")
print("ĞŸĞ»Ğ¾Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ²ÑĞ·ÑƒÑÑ‰Ğ¸Ñ… ÑĞ»Ğ¾Ğ² (ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ñ‚Ñ‹ÑÑÑ‡Ñƒ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)")
total_conn = sum(connectors.values())
print(f"  Ğ’ÑĞµĞ³Ğ¾: {total_conn}  | ĞÑ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğµ: {ratio(total_conn):.2f}")
for k,v in sorted(connectors.items(), key=lambda x: -x[1])[:10]:
  if v>0: print(f"  - {k}: {v}")

print("")
print("ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿ÑƒÑÑ‚Ñ‹Ñ…/ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ·")
total_emp = sum(empties.values())
print(f"  Ğ’ÑĞµĞ³Ğ¾: {total_emp}  | ĞÑ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğµ: {ratio(total_emp):.2f}")
for k,v in sorted(empties.items(), key=lambda x: -x[1])[:10]:
  if v>0: print(f"  - {k}: {v}")

print("")
print("Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹")
print(f"  ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹: {len(lens)}  | Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ: {avg:.1f}  | Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ: {std:.1f}")
print(f"  ĞœĞ°ĞºÑ. Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹: {mx_run_short} (Ğ¿Ğ¾Ñ€Ğ¾Ğ³ {cfg['sentence_length']['max_run_short']})")
print(f"  ĞœĞ°ĞºÑ. Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹: {mx_run_long} (Ğ¿Ğ¾Ñ€Ğ¾Ğ³ {cfg['sentence_length']['max_run_long']})")

print("")
print("ĞĞ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºĞ° (Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ², â‰¥2 Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ‹Ñ… ÑĞ»Ğ¾Ğ²Ğ°)")
if abstract_top:
  for idx, s in abstract_top:
    snippet = s[:80] + ("â€¦" if len(s)>80 else "")
    print(f"  - ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â„–{idx+1}: {snippet}")
else:
  print("  ĞĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºĞ¾Ğ¹")

print("")
print("Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸")
print("  - Ğ—Ğ°Ğ¼ĞµĞ½ÑĞ¹Ñ‚Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ Ñ„Ñ€Ğ°Ğ·Ñ‹ Ğ¸ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ‹Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑĞ¼Ğ¸/Ğ¿Ñ€ĞµĞ´Ğ¼ĞµÑ‚Ğ°Ğ¼Ğ¸/Ğ·Ğ°Ğ¿Ğ°Ñ…Ğ°Ğ¼Ğ¸")
print("  - Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°Ğ¹Ñ‚Ğµ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ; Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞ¹Ñ‚Ğµ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ñ€Ğ¸Ñ‚Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ")
print("  - ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ»Ğ¸ ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ ÑĞ²ÑĞ·ÑƒÑÑ‰Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ¸Ğ»Ğ¸ Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¸Ñ… Ğ±Ğ¾Ğ»ĞµĞµ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ°Ğ¼Ğ¸")
print("  - ĞŸĞµÑ€ĞµĞ´ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ· 3 Ğ¶Ğ¸Ğ·Ğ½ĞµĞ½Ğ½Ñ‹Ñ… Ğ´ĞµÑ‚Ğ°Ğ»ĞµĞ¹ Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾Ğ¿Ğ¾Ñ€Ğ½Ñ‹Ñ… Ñ‚Ğ¾Ñ‡ĞµĞº")
print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
PY
```